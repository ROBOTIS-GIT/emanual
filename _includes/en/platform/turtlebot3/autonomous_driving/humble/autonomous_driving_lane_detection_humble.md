## [Lane Detection](#lane-detection)

Lane detection allows the TurtleBot3 to recognize lane markings and follow them autonomously. The system processes camera images from either a real TurtleBot3 or Gazebo simulation, applies color filtering, and identifies lane boundaries.

<iframe width="560" height="315" src="https://www.youtube.com/embed/IqV4huXGBEk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>

This section explains how to launch the lane detection system, visualize the detected lane markings, and calibrate the parameters to ensure accurate tracking.
<br>

**Launching Lane Detection in Simulation**

To begin, start the Gazebo simulation with a pre-defined lane-tracking course:
``` bash
$ ros2 launch turtlebot3_gazebo turtlebot3_autorace_2020.launch.py
```  
Next, run the camera calibration processes, which ensure that the detected lanes are accurately mapped to the robotâ€™s perspective:
``` bash
$ ros2 launch turtlebot3_autorace_camera intrinsic_camera_calibration.launch.py
```  
``` bash
$ ros2 launch turtlebot3_autorace_camera extrinsic_camera_calibration.launch.py
```  
These steps activate intrinsic and extrinsic calibration to correct any distortions in the camera feed.

Finally, launch the lane detection node in calibration mode to begin detecting lanes:
``` bash
$ ros2 launch turtlebot3_autorace_detect detect_lane.launch.py calibration_mode:=True
```  
<br>

**Visualizing Lane Detection Output**

To inspect the detected lanes, open rqt on `Remote PC`:
``` bash
$ rqt
```  
Then navigate to **Plugins** > **Visualization** > **Image View** and open three image viewers to display different lane detection results:
  - `/detect/image_lane/compressed`  
  ![](/assets/images/platform/turtlebot3/autonomous_driving/noetic_detect_image_lane.png)
  - `/detect/image_yellow_lane_marker/compressed` : a yellow range color filtered image.  
  ![](/assets/images/platform/turtlebot3/autonomous_driving/noetic_detect_yellow_lane.png)
  - `/detect/image_white_lane_marker/compressed` : a white range color filtered image.  
  ![](/assets/images/platform/turtlebot3/autonomous_driving/noetic_detect_white_lane.png)

These visualizations help confirm that the lane detection algorithm is correctly identifying lane boundaries.
<br><br>

**Calibrating Lane Detection Parameters**

For optimal accuracy, tuning detection parameters is necessary. Adjusting these parameters ensures the robot properly identifies lanes under different lighting and environmental conditions.

1. Open the **lane.yaml** file located in **turtlebot3_autorace_detect/param/lane/** and write your modified values to this file. This will ensure the camera uses the modified parameters for future launches.
    ``` bash
    $ cd ~/turtlebot3_ws/src/turtlebot3_autorace/turtlebot3_autorace_detect/param/lane
    $ gedit lane.yaml
    ```  
    ![](/assets/images/platform/turtlebot3/autonomous_driving/humble_lane_yaml.png)
    > Modified lane.yaml file

<br>

**Running Lane Tracking**

Once calibration is complete, restart the lane detection node without the calibration option:
```bash
$ ros2 launch turtlebot3_autorace_detect detect_lane.launch.py
```

Then, launch the lane following control node, which enables TurtleBot3 to automatically follow the detected lanes:
```bash
$ ros2 launch turtlebot3_autorace_mission control_lane.launch.py
```
